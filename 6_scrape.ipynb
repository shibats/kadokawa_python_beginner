{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.天気予報のWebサイトをスクレイピングする\n",
    "\n",
    "tenki.jp( https://tenki.jp/ )をスクレイピングする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをインポート\n",
    "from urllib.request import urlopen # Webページ読み込み用関数\n",
    "from bs4 import BeautifulSoup        # スクレイピングライブラリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 東京都(千代田区)の天気予報を読み込む\n",
    "r = urlopen(\"https://tenki.jp/forecast/3/16/4410/13101/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhtml = r.read()   # HTMLを文字列(バイト文字列)として読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エンコードを指定してバイト型を文字列型に変換\n",
    "html = bhtml.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## soupオブジェクトを使う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# スクレイピング用オブジェクト(soupオブジェクト)を作る\n",
    "soup = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soupオブジェクトを使って，タグ(エレメント)を検索する\n",
    "# find_all()メソッドを使う。引数に，タグ名(div)を文字列として渡す\n",
    "divs = soup.find_all(\"div\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divsには，HTML内のdivタグがすべて返ってくる\n",
    "# divタグは複数あるので，リストとして返ってくる\n",
    "\n",
    "len(divs)   # divタグの数を数えてみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divs[24]   # 0から数えて24番目のdivタグを表示してみる(文字列が表示される)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "navdiv = divs[24] # 実は検索結果もsoupオブジェクト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "navdiv.find_all('dd') # 検索結果を取り出し，さらにその子供だけを検索できる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 「属性」と「属性値」を使った検索\n",
    "\n",
    "HTMLの属性とは，「＜div id=\"foo\">」の「id=\"foo\"」の部分や，「＜span class=\"bar\">」の「class=\"bar\"」のようなタグ内部の部分。\n",
    "\n",
    "「id」や「class」を「属性名」と呼び，「=\"~\"」の引用符の中を「属性値」と呼ぶ。\n",
    "\n",
    "たとえば，先ほど取り出したdivタグには，「class=\"weather-wrap clearfix\"」という属性と属性値がある。この文字列を使って要素を検索できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML全体を指すsoupオブジェクトを使って検索\n",
    "\n",
    "# タグ名div, classが\"weather-wrap clearfix\"の要素を検索する\n",
    "# class_=\"weather-wrap clearfix\"というように引数を指定するのがポイント\n",
    "# ※検索時にclass属性を指定する時は，「class_=\"...\"」とする(「class=\"..\"」ではないので注意)\n",
    "\n",
    "navdiv = soup.find_all(\"div\", class_=\"weather-wrap clearfix\") \n",
    "navdiv  # 先ほど取り出したゼロから数えて24番目のdivと同じ要素が返ってくる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テキストの取り出し\n",
    "\n",
    "普通，タグにはスクレイピングに必要な情報は入っていない。「<span>テキスト</span>」のようにタグに囲まれた部分に，必要な文字列が入っている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_l = soup.find_all(\"div\", class_=\"weather-wrap clearfix\")  # 今日の天気を含むdiv要素を取り出す\n",
    "# リストが返ってくるので，インデックスを指定して一つの要素を取り出す\n",
    "today = today_l[0]\n",
    "today  # 表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today.text   # タグに囲まれたテキスト部分だけを取り出す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 天気予報のテキストだけが欲しいので，さらに絞り込む\n",
    "# 天気は\"weather-telop\"というclass属性に入っている\n",
    "weather_l = today.find_all(\"p\", class_=\"weather-telop\")\n",
    "weather = weather_l[0]  # リストが返ってくるのでインデックスで最初の要素を取り出す\n",
    "weather   # 表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherstr = weather.text  # タグで囲まれたテキストを取り出す\n",
    "weatherstr   # 表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## スクレイピングのベストプラクティス\n",
    "\n",
    "### 一発で取り出す\n",
    "\n",
    "取り出したいテキストを含むタグを一発で取り出せるよう，タグ名やid, class_などを使ってfind_all()で取り出せるか考える。\n",
    "\n",
    "### 絞り込んで取り出す\n",
    "\n",
    "取り出したいテキストの親にあたるタグをfind_all()で取り出し，さらに絞り込んで取り出す。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライブコーディングでスクレイピングをするプログラムを書いてみる\n",
    "\n",
    "### 目標1\n",
    "\n",
    "東京の今日の天気スクレイピングで取り出す。\n",
    "\n",
    "「今日の天気は~」という文字列を組み立てる。\n",
    "\n",
    "### 目標2\n",
    "\n",
    "- 明日の天気も取り出し「明日の天気は~」という文字列を追加する\n",
    "\n",
    "- できた文字列をgttsで喋らせる\n",
    "\n",
    "### 目標3\n",
    "\n",
    "課題1を参考に，エキサイト天気予報のURLを文字列で受け取り，今日の天気を文字列として組み立てる関数を作る。関数名は「get_weather」とする。\n",
    "\n",
    "関数から「return 変数」のようにして文字列を「戻り値」として戻す。\n",
    "\n",
    "関数に別の地域のURLを渡して，天気予報の文字列を得られるようにする。\n",
    "\n",
    "### 目標4\n",
    "\n",
    "- 明日の天気も取り出し「明日の天気は~」という文字列を追加する\n",
    "\n",
    "- 得た文字列をgttsで喋らせる。\n",
    "\n",
    "- いろいろな地域の天気を喋らせてみる。\n",
    "\n",
    "- 地域の名前(「東京都 伊豆諸島北部(大島)」など)を取り出し，関数で組み立てる文字列の先頭に追加する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL文字列を変数に代入\n",
    "url = \"https://tenki.jp/forecast/3/16/4410/13101/\"\n",
    "\n",
    "# 東京の天気予報を読み込む\n",
    "r = urlopen(url)\n",
    "bhtml = r.read()   # HTMLを文字列(バイト文字列)として読み込む\n",
    "# エンコードを指定してバイト型を文字列型に変換\n",
    "html = bhtml.decode(\"utf-8\")\n",
    "\n",
    "# スクレイピング用オブジェクト(soupオブジェクト)を作る\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# 今日の天気を含むdiv要素を取り出す\n",
    "today_l = soup.find_all(\"div\", class_=\"weather-wrap clearfix\")\n",
    "# リストが返ってくるので，インデックスを指定して一つの要素を取り出す\n",
    "today = today_l[0]\n",
    "\n",
    "weather_l = today.find_all(\"p\", class_=\"weather-telop\")\n",
    "weather = weather_l[0]  # リストが返ってくるのでインデックスで最初の要素を取り出す\n",
    "weatherstr = weather.text  # タグで囲まれたテキストを取り出す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
